{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm_joblib import tqdm_joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('asl-signs/train.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TV': 0, 'after': 1, 'airplane': 2, 'all': 3, 'alligator': 4, 'animal': 5, 'another': 6, 'any': 7, 'apple': 8, 'arm': 9, 'aunt': 10, 'awake': 11, 'backyard': 12, 'bad': 13, 'balloon': 14, 'bath': 15, 'because': 16, 'bed': 17, 'bedroom': 18, 'bee': 19, 'before': 20, 'beside': 21, 'better': 22, 'bird': 23, 'black': 24, 'blow': 25, 'blue': 26, 'boat': 27, 'book': 28, 'boy': 29, 'brother': 30, 'brown': 31, 'bug': 32, 'bye': 33, 'callonphone': 34, 'can': 35, 'car': 36, 'carrot': 37, 'cat': 38, 'cereal': 39, 'chair': 40, 'cheek': 41, 'child': 42, 'chin': 43, 'chocolate': 44, 'clean': 45, 'close': 46, 'closet': 47, 'cloud': 48, 'clown': 49, 'cow': 50, 'cowboy': 51, 'cry': 52, 'cut': 53, 'cute': 54, 'dad': 55, 'dance': 56, 'dirty': 57, 'dog': 58, 'doll': 59, 'donkey': 60, 'down': 61, 'drawer': 62, 'drink': 63, 'drop': 64, 'dry': 65, 'dryer': 66, 'duck': 67, 'ear': 68, 'elephant': 69, 'empty': 70, 'every': 71, 'eye': 72, 'face': 73, 'fall': 74, 'farm': 75, 'fast': 76, 'feet': 77, 'find': 78, 'fine': 79, 'finger': 80, 'finish': 81, 'fireman': 82, 'first': 83, 'fish': 84, 'flag': 85, 'flower': 86, 'food': 87, 'for': 88, 'frenchfries': 89, 'frog': 90, 'garbage': 91, 'gift': 92, 'giraffe': 93, 'girl': 94, 'give': 95, 'glasswindow': 96, 'go': 97, 'goose': 98, 'grandma': 99, 'grandpa': 100, 'grass': 101, 'green': 102, 'gum': 103, 'hair': 104, 'happy': 105, 'hat': 106, 'hate': 107, 'have': 108, 'haveto': 109, 'head': 110, 'hear': 111, 'helicopter': 112, 'hello': 113, 'hen': 114, 'hesheit': 115, 'hide': 116, 'high': 117, 'home': 118, 'horse': 119, 'hot': 120, 'hungry': 121, 'icecream': 122, 'if': 123, 'into': 124, 'jacket': 125, 'jeans': 126, 'jump': 127, 'kiss': 128, 'kitty': 129, 'lamp': 130, 'later': 131, 'like': 132, 'lion': 133, 'lips': 134, 'listen': 135, 'look': 136, 'loud': 137, 'mad': 138, 'make': 139, 'man': 140, 'many': 141, 'milk': 142, 'minemy': 143, 'mitten': 144, 'mom': 145, 'moon': 146, 'morning': 147, 'mouse': 148, 'mouth': 149, 'nap': 150, 'napkin': 151, 'night': 152, 'no': 153, 'noisy': 154, 'nose': 155, 'not': 156, 'now': 157, 'nuts': 158, 'old': 159, 'on': 160, 'open': 161, 'orange': 162, 'outside': 163, 'owie': 164, 'owl': 165, 'pajamas': 166, 'pen': 167, 'pencil': 168, 'penny': 169, 'person': 170, 'pig': 171, 'pizza': 172, 'please': 173, 'police': 174, 'pool': 175, 'potty': 176, 'pretend': 177, 'pretty': 178, 'puppy': 179, 'puzzle': 180, 'quiet': 181, 'radio': 182, 'rain': 183, 'read': 184, 'red': 185, 'refrigerator': 186, 'ride': 187, 'room': 188, 'sad': 189, 'same': 190, 'say': 191, 'scissors': 192, 'see': 193, 'shhh': 194, 'shirt': 195, 'shoe': 196, 'shower': 197, 'sick': 198, 'sleep': 199, 'sleepy': 200, 'smile': 201, 'snack': 202, 'snow': 203, 'stairs': 204, 'stay': 205, 'sticky': 206, 'store': 207, 'story': 208, 'stuck': 209, 'sun': 210, 'table': 211, 'talk': 212, 'taste': 213, 'thankyou': 214, 'that': 215, 'there': 216, 'think': 217, 'thirsty': 218, 'tiger': 219, 'time': 220, 'tomorrow': 221, 'tongue': 222, 'tooth': 223, 'toothbrush': 224, 'touch': 225, 'toy': 226, 'tree': 227, 'uncle': 228, 'underwear': 229, 'up': 230, 'vacuum': 231, 'wait': 232, 'wake': 233, 'water': 234, 'wet': 235, 'weus': 236, 'where': 237, 'white': 238, 'who': 239, 'why': 240, 'will': 241, 'wolf': 242, 'yellow': 243, 'yes': 244, 'yesterday': 245, 'yourself': 246, 'yucky': 247, 'zebra': 248, 'zipper': 249}\n"
     ]
    }
   ],
   "source": [
    "label_map = json.load(open('asl-signs/sign_to_prediction_index_map.json'))\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_check(df):\n",
    "    min = df['frame'].min()\n",
    "    max = df['frame'].max()\n",
    "    if (max-min) < 5:\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_count(df):\n",
    "    min = df['frame'].min()\n",
    "    max = df['frame'].max()\n",
    "    return max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_file(filename):\n",
    "    # start = timeit.default_timer()\n",
    "    df_tmp = pq.read_table(f'asl-signs/{filename}').to_pandas()\n",
    "    if not frame_check(df_tmp):\n",
    "        return np.array([0]), False\n",
    "    df_tmp = df_tmp.fillna(0)\n",
    "    face_landmarks = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, \n",
    "                     291, 146, 91, 181, 84, 17, 314, 405, 321, 375,  \n",
    "                     191, 80, 81, 82, 13, 312, 311, 310, 415, 308, \n",
    "                     95, 88, 178, 87, 14, 317, 402, 318, 324]\n",
    "    pose_landmarks = [11, 12, 13, 14, 15, 16,\n",
    "                      17, 18, 19, 20, 21, 22]\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    all_list = []\n",
    "    hand = ['left_hand', 'right_hand']\n",
    "    tmp_frame = 0\n",
    "    max_f, min = frame_count(df_tmp)\n",
    "    frames = max_f-min+1\n",
    "    df_tmp = df_tmp.query('type == @hand or (type == \"face\" & landmark_index == @face_landmarks) or (type == \"pose\" & landmark_index == @pose_landmarks) ')\n",
    "    if frames > 20:\n",
    "        buff = max_f-20\n",
    "        df_tmp = df_tmp.query('frame >= @buff')\n",
    "        for i in range(max_f-19, max_f+1):\n",
    "            tmp_df = df_tmp.query('frame == @i')\n",
    "            all_list.append(np.array([tmp_df['x'].astype(np.float32).to_numpy(), tmp_df['y'].astype(np.float32).to_numpy(), tmp_df['z'].astype(np.float32).to_numpy()]).flatten())\n",
    "    else:\n",
    "        for i in range(min, max_f+1):\n",
    "            tmp_df = df_tmp.query('frame == @i')\n",
    "            all_list.append(np.array([tmp_df['x'].astype(np.float32).to_numpy(), tmp_df['y'].astype(np.float32).to_numpy(), tmp_df['z'].astype(np.float32).to_numpy()]).flatten())\n",
    "    ret = np.array(all_list).shape[0]\n",
    "    if ret < 20:\n",
    "        add_list = [[0 for i in range(279)] for j in range(20-ret)]\n",
    "        all_list = add_list + all_list\n",
    "    # print(timeit.default_timer() - start)\n",
    "    shp = np.array(all_list).shape\n",
    "    try:\n",
    "        if shp[0] != 20 or shp[1]!= 279:\n",
    "            print(np.array(all_list).shape)\n",
    "    except:\n",
    "        return np.array([0]), False       \n",
    "    else:\n",
    "        if shp[0] != 20 or shp[1]!= 279:\n",
    "            print(np.array(all_list).shape)\n",
    "        return np.asarray(all_list), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(raw):\n",
    "    return label_map[raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d78ed816ea544afbe6820f6407bab91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label conversion:   0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff721dc5dc1741399c5201b79f617a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data conversion:   0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/var/folders/vt/q06w72ls4kz7lg_wsqqw2f0h0000gp/T/ipykernel_85603/3475926203.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# Parallelism\n",
    "\n",
    "path = df['path'].to_numpy().astype(str)\n",
    "raw_label = df['sign'].to_numpy().astype(str)\n",
    "with tqdm_joblib(desc=\"Label conversion\", total=94477) as progress_bar:\n",
    "    label = Parallel(n_jobs=-1)(delayed(convert_label)(i) for i in raw_label)\n",
    "with tqdm_joblib(desc=\"Data conversion\", total=94477) as progress_bar:\n",
    "    data, cond = zip(*Parallel(n_jobs=-1)(delayed(extract_file)(i) for i in path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>cond</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.5064058, 0.50869834, 0.50817716, 0.5090293...</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>True</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.40560728, 0.40628085, 0.40590265, 0.404934...</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>True</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>[[0.49037775, 0.49069953, 0.49301714, 0.493240...</td>\n",
       "      <td>True</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>[[0.51680005, 0.515573, 0.51561564, 0.5125802,...</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>[[0.47087848, 0.47033817, 0.4701829, 0.4695914...</td>\n",
       "      <td>True</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>[[0.43693373, 0.43924746, 0.4425436, 0.4459135...</td>\n",
       "      <td>True</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  cond label\n",
       "0      [[0.5064058, 0.50869834, 0.50817716, 0.5090293...  True    25\n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  True   232\n",
       "2      [[0.40560728, 0.40628085, 0.40590265, 0.404934...  True    48\n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  True    23\n",
       "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  True   164\n",
       "...                                                  ...   ...   ...\n",
       "94472  [[0.49037775, 0.49069953, 0.49301714, 0.493240...  True   238\n",
       "94473  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  True   108\n",
       "94474  [[0.51680005, 0.515573, 0.51561564, 0.5125802,...  True    86\n",
       "94475  [[0.47087848, 0.47033817, 0.4701829, 0.4695914...  True   188\n",
       "94476  [[0.43693373, 0.43924746, 0.4425436, 0.4459135...  True   105\n",
       "\n",
       "[94477 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing false data\n",
    "new_df = pd.DataFrame(data=[data, cond, label]).T\n",
    "new_df.columns = ['data', 'cond', 'label']\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.5064058, 0.50869834, 0.50817716, 0.5090293...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.40560728, 0.40628085, 0.40590265, 0.404934...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94099</th>\n",
       "      <td>[[0.49037775, 0.49069953, 0.49301714, 0.493240...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94100</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94101</th>\n",
       "      <td>[[0.51680005, 0.515573, 0.51561564, 0.5125802,...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94102</th>\n",
       "      <td>[[0.47087848, 0.47033817, 0.4701829, 0.4695914...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94103</th>\n",
       "      <td>[[0.43693373, 0.43924746, 0.4425436, 0.4459135...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94104 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data label\n",
       "0      [[0.5064058, 0.50869834, 0.50817716, 0.5090293...    25\n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   232\n",
       "2      [[0.40560728, 0.40628085, 0.40590265, 0.404934...    48\n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    23\n",
       "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   164\n",
       "...                                                  ...   ...\n",
       "94099  [[0.49037775, 0.49069953, 0.49301714, 0.493240...   238\n",
       "94100  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   108\n",
       "94101  [[0.51680005, 0.515573, 0.51561564, 0.5125802,...    86\n",
       "94102  [[0.47087848, 0.47033817, 0.4701829, 0.4695914...   188\n",
       "94103  [[0.43693373, 0.43924746, 0.4425436, 0.4459135...   105\n",
       "\n",
       "[94104 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[new_df.cond != False]\n",
    "new_df = new_df.drop(['cond'], axis=1)\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94104, 20, 279)\n",
      "(94104, 250)\n"
     ]
    }
   ],
   "source": [
    "X_data = [data for data in new_df['data'].to_numpy()]\n",
    "X_data = np.array(X_data)\n",
    "print(X_data.shape)\n",
    "Y_data = [label for label in new_df['label'].to_numpy()]\n",
    "Y_data = np.array(Y_data)\n",
    "Y_data = to_categorical(Y_data).astype(int)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"feature_data.npy\", X_data)\n",
    "np.save(\"label_data.npy\", Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.load(\"feature_data.npy\")\n",
    "Y_data = np.load(\"label_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X, y_train, y = train_test_split(X_data, Y_data, test_size=0.1, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84693, 20, 279)\n",
      "(84693, 250)\n",
      "(4705, 20, 279)\n",
      "(4705, 250)\n",
      "(4706, 20, 279)\n",
      "(4706, 250)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten, GRU, Conv1D\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainingCallback(Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    \n",
    "    # Check accuracy\n",
    "    # if(logs.get('categorical_accuracy') < 0.95  and logs.get('loss') < 0.35 and logs.get('val_loss') < 0.35):\n",
    "    if((logs.get('categorical_accuracy') > 0.95) or (logs.get('categorical_accuracy') > 0.92  and logs.get('loss') > logs.get('val_loss'))):\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\nAccuracy grater than 0.92 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = trainingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20, 279)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 256),        548864      ['input_3[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 256)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 768)          0           ['dropout_4[0][0]',              \n",
      "                                                                  'lstm_2[0][1]',                 \n",
      "                                                                  'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          393728      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 512)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 250)          128250      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,070,842\n",
      "Trainable params: 1,070,842\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "inputs = tf.keras.layers.Input(shape=(20,279))\n",
    "x_1, w, h = tf.keras.layers.LSTM(256, return_sequences=False, activation='relu', return_state=True)(inputs)\n",
    "x = tf.keras.layers.Dropout(0.2)(x_1)\n",
    "# x = tf.keras.layers.LSTM(128, return_sequences=False, activation='relu')(x, initial_state=[w, h])\n",
    "concat = tf.keras.layers.concatenate([x, w, h])\n",
    "# flatten = tf.keras.layers.Flatten(concat)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(concat)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "out = tf.keras.layers.Dense(250, activation='softmax', name='outputs')(x)\n",
    "model_LSTM = tf.keras.Model(inputs, out)\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1324/1324 [==============================] - 54s 40ms/step - loss: 4.9970 - categorical_accuracy: 0.0291 - val_loss: 4.3978 - val_categorical_accuracy: 0.0829\n",
      "Epoch 2/200\n",
      "1324/1324 [==============================] - 58s 44ms/step - loss: 4.1398 - categorical_accuracy: 0.1076 - val_loss: 3.8806 - val_categorical_accuracy: 0.1528\n",
      "Epoch 3/200\n",
      "1324/1324 [==============================] - 55s 42ms/step - loss: 3.7750 - categorical_accuracy: 0.1592 - val_loss: 3.5856 - val_categorical_accuracy: 0.2012\n",
      "Epoch 4/200\n",
      "1324/1324 [==============================] - 58s 44ms/step - loss: 3.4880 - categorical_accuracy: 0.2058 - val_loss: 3.3766 - val_categorical_accuracy: 0.2378\n",
      "Epoch 5/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 3.2698 - categorical_accuracy: 0.2440 - val_loss: 3.1624 - val_categorical_accuracy: 0.2835\n",
      "Epoch 6/200\n",
      "1324/1324 [==============================] - 53s 40ms/step - loss: 3.1221 - categorical_accuracy: 0.2716 - val_loss: 3.0807 - val_categorical_accuracy: 0.2935\n",
      "Epoch 7/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 3.0082 - categorical_accuracy: 0.2943 - val_loss: 2.9834 - val_categorical_accuracy: 0.3177\n",
      "Epoch 8/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 2.9121 - categorical_accuracy: 0.3122 - val_loss: 2.9468 - val_categorical_accuracy: 0.3217\n",
      "Epoch 9/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 2.8245 - categorical_accuracy: 0.3308 - val_loss: 2.9216 - val_categorical_accuracy: 0.3281\n",
      "Epoch 10/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 2.7634 - categorical_accuracy: 0.3426 - val_loss: 2.8596 - val_categorical_accuracy: 0.3394\n",
      "Epoch 11/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.6911 - categorical_accuracy: 0.3565 - val_loss: 2.7524 - val_categorical_accuracy: 0.3687\n",
      "Epoch 12/200\n",
      "1324/1324 [==============================] - 55s 42ms/step - loss: 2.6430 - categorical_accuracy: 0.3655 - val_loss: 2.7921 - val_categorical_accuracy: 0.3678\n",
      "Epoch 13/200\n",
      "1324/1324 [==============================] - 54s 41ms/step - loss: 2.5872 - categorical_accuracy: 0.3761 - val_loss: 2.7275 - val_categorical_accuracy: 0.3776\n",
      "Epoch 14/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.5390 - categorical_accuracy: 0.3838 - val_loss: 2.6637 - val_categorical_accuracy: 0.3965\n",
      "Epoch 15/200\n",
      "1324/1324 [==============================] - 56s 42ms/step - loss: 2.5114 - categorical_accuracy: 0.3930 - val_loss: 2.7180 - val_categorical_accuracy: 0.3744\n",
      "Epoch 16/200\n",
      "1324/1324 [==============================] - 54s 41ms/step - loss: 2.4569 - categorical_accuracy: 0.4045 - val_loss: 2.6985 - val_categorical_accuracy: 0.3850\n",
      "Epoch 17/200\n",
      "1324/1324 [==============================] - 54s 41ms/step - loss: 2.4206 - categorical_accuracy: 0.4092 - val_loss: 2.6432 - val_categorical_accuracy: 0.4035\n",
      "Epoch 18/200\n",
      "1324/1324 [==============================] - 54s 41ms/step - loss: 2.3887 - categorical_accuracy: 0.4163 - val_loss: 2.6171 - val_categorical_accuracy: 0.4116\n",
      "Epoch 19/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.3500 - categorical_accuracy: 0.4258 - val_loss: 2.5857 - val_categorical_accuracy: 0.4095\n",
      "Epoch 20/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.3220 - categorical_accuracy: 0.4315 - val_loss: 2.5809 - val_categorical_accuracy: 0.4163\n",
      "Epoch 21/200\n",
      "1324/1324 [==============================] - 64s 48ms/step - loss: 2.2950 - categorical_accuracy: 0.4358 - val_loss: 2.6935 - val_categorical_accuracy: 0.3893\n",
      "Epoch 22/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.2655 - categorical_accuracy: 0.4437 - val_loss: 2.5871 - val_categorical_accuracy: 0.4165\n",
      "Epoch 23/200\n",
      "1324/1324 [==============================] - 54s 40ms/step - loss: 2.2415 - categorical_accuracy: 0.4470 - val_loss: 2.5961 - val_categorical_accuracy: 0.4091\n",
      "Epoch 24/200\n",
      "1324/1324 [==============================] - 54s 40ms/step - loss: 2.2117 - categorical_accuracy: 0.4517 - val_loss: 2.6306 - val_categorical_accuracy: 0.4093\n",
      "Epoch 25/200\n",
      "1324/1324 [==============================] - 54s 41ms/step - loss: 2.1912 - categorical_accuracy: 0.4570 - val_loss: 2.5969 - val_categorical_accuracy: 0.4142\n",
      "Epoch 26/200\n",
      "1324/1324 [==============================] - 55s 41ms/step - loss: 2.1632 - categorical_accuracy: 0.4630 - val_loss: 2.5904 - val_categorical_accuracy: 0.4220\n",
      "Epoch 27/200\n",
      "1324/1324 [==============================] - 55s 42ms/step - loss: 2.1413 - categorical_accuracy: 0.4702 - val_loss: 2.5658 - val_categorical_accuracy: 0.4246\n",
      "Epoch 28/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 2.1198 - categorical_accuracy: 0.4737 - val_loss: 2.5282 - val_categorical_accuracy: 0.4401\n",
      "Epoch 29/200\n",
      "1324/1324 [==============================] - 59s 45ms/step - loss: 2.1081 - categorical_accuracy: 0.4737 - val_loss: 2.5142 - val_categorical_accuracy: 0.4454\n",
      "Epoch 30/200\n",
      "1324/1324 [==============================] - 58s 44ms/step - loss: 2.0883 - categorical_accuracy: 0.4797 - val_loss: 2.5303 - val_categorical_accuracy: 0.4399\n",
      "Epoch 31/200\n",
      "1324/1324 [==============================] - 65s 49ms/step - loss: 2.0628 - categorical_accuracy: 0.4839 - val_loss: 2.5822 - val_categorical_accuracy: 0.4348\n",
      "Epoch 32/200\n",
      "1324/1324 [==============================] - 65s 49ms/step - loss: 2.0482 - categorical_accuracy: 0.4874 - val_loss: 2.4873 - val_categorical_accuracy: 0.4397\n",
      "Epoch 33/200\n",
      "1324/1324 [==============================] - 64s 48ms/step - loss: 2.0225 - categorical_accuracy: 0.4919 - val_loss: 2.5404 - val_categorical_accuracy: 0.4358\n",
      "Epoch 34/200\n",
      "1324/1324 [==============================] - 62s 47ms/step - loss: 2.0087 - categorical_accuracy: 0.4963 - val_loss: 2.6335 - val_categorical_accuracy: 0.4350\n",
      "Epoch 35/200\n",
      "1324/1324 [==============================] - 73s 55ms/step - loss: 1.9892 - categorical_accuracy: 0.4984 - val_loss: 2.5311 - val_categorical_accuracy: 0.4516\n",
      "Epoch 36/200\n",
      "1324/1324 [==============================] - 87s 66ms/step - loss: 1.9795 - categorical_accuracy: 0.5010 - val_loss: 2.5281 - val_categorical_accuracy: 0.4520\n",
      "Epoch 37/200\n",
      "1324/1324 [==============================] - 91s 69ms/step - loss: 1.9601 - categorical_accuracy: 0.5063 - val_loss: 2.6454 - val_categorical_accuracy: 0.4411\n",
      "Epoch 38/200\n",
      "1324/1324 [==============================] - 117s 88ms/step - loss: 1.9449 - categorical_accuracy: 0.5075 - val_loss: 2.5091 - val_categorical_accuracy: 0.4545\n",
      "Epoch 39/200\n",
      "1324/1324 [==============================] - 111s 84ms/step - loss: 1.9344 - categorical_accuracy: 0.5105 - val_loss: 2.5137 - val_categorical_accuracy: 0.4624\n",
      "Epoch 40/200\n",
      "1324/1324 [==============================] - 125s 95ms/step - loss: 1.9117 - categorical_accuracy: 0.5173 - val_loss: 2.5170 - val_categorical_accuracy: 0.4586\n",
      "Epoch 41/200\n",
      "1324/1324 [==============================] - 135s 102ms/step - loss: 1.9021 - categorical_accuracy: 0.5171 - val_loss: 2.5189 - val_categorical_accuracy: 0.4639\n",
      "Epoch 42/200\n",
      "1324/1324 [==============================] - 281s 212ms/step - loss: 1.8945 - categorical_accuracy: 0.5201 - val_loss: 2.5221 - val_categorical_accuracy: 0.4611\n",
      "Epoch 43/200\n",
      "1324/1324 [==============================] - 320s 241ms/step - loss: 1.8775 - categorical_accuracy: 0.5211 - val_loss: 2.5222 - val_categorical_accuracy: 0.4601\n",
      "Epoch 44/200\n",
      "1324/1324 [==============================] - 153s 115ms/step - loss: 1.8633 - categorical_accuracy: 0.5259 - val_loss: 2.5642 - val_categorical_accuracy: 0.4577\n",
      "Epoch 45/200\n",
      "1324/1324 [==============================] - 73s 55ms/step - loss: 1.8557 - categorical_accuracy: 0.5277 - val_loss: 2.5874 - val_categorical_accuracy: 0.4526\n",
      "Epoch 46/200\n",
      "1324/1324 [==============================] - 64s 49ms/step - loss: 1.8486 - categorical_accuracy: 0.5282 - val_loss: 2.6057 - val_categorical_accuracy: 0.4450\n",
      "Epoch 47/200\n",
      "1324/1324 [==============================] - 64s 49ms/step - loss: 1.8342 - categorical_accuracy: 0.5295 - val_loss: 2.5977 - val_categorical_accuracy: 0.4577\n",
      "Epoch 48/200\n",
      "1324/1324 [==============================] - 62s 47ms/step - loss: 1.8208 - categorical_accuracy: 0.5321 - val_loss: 2.6388 - val_categorical_accuracy: 0.4622\n",
      "Epoch 49/200\n",
      "1324/1324 [==============================] - 63s 47ms/step - loss: 1.8094 - categorical_accuracy: 0.5368 - val_loss: 2.5446 - val_categorical_accuracy: 0.4649\n",
      "Epoch 50/200\n",
      "1324/1324 [==============================] - 63s 47ms/step - loss: 1.7965 - categorical_accuracy: 0.5419 - val_loss: 2.5632 - val_categorical_accuracy: 0.4618\n",
      "Epoch 51/200\n",
      "1324/1324 [==============================] - 65s 49ms/step - loss: 1.7866 - categorical_accuracy: 0.5434 - val_loss: 2.6154 - val_categorical_accuracy: 0.4711\n",
      "Epoch 52/200\n",
      "1324/1324 [==============================] - 64s 49ms/step - loss: 1.7728 - categorical_accuracy: 0.5452 - val_loss: 2.6358 - val_categorical_accuracy: 0.4601\n",
      "Epoch 53/200\n",
      "1324/1324 [==============================] - 64s 48ms/step - loss: 1.7692 - categorical_accuracy: 0.5440 - val_loss: 2.5241 - val_categorical_accuracy: 0.4756\n",
      "Epoch 54/200\n",
      "1324/1324 [==============================] - 63s 48ms/step - loss: 1.7683 - categorical_accuracy: 0.5435 - val_loss: 2.5655 - val_categorical_accuracy: 0.4700\n",
      "Epoch 55/200\n",
      "1324/1324 [==============================] - 62s 47ms/step - loss: 1.7478 - categorical_accuracy: 0.5497 - val_loss: 2.5972 - val_categorical_accuracy: 0.4730\n",
      "Epoch 56/200\n",
      "1324/1324 [==============================] - 63s 48ms/step - loss: 1.7372 - categorical_accuracy: 0.5510 - val_loss: 2.6277 - val_categorical_accuracy: 0.4645\n",
      "Epoch 57/200\n",
      "1324/1324 [==============================] - 64s 48ms/step - loss: 1.7324 - categorical_accuracy: 0.5512 - val_loss: 2.7084 - val_categorical_accuracy: 0.4441\n",
      "Epoch 58/200\n",
      "1324/1324 [==============================] - 66s 50ms/step - loss: 1.7304 - categorical_accuracy: 0.5548 - val_loss: 2.5918 - val_categorical_accuracy: 0.4607\n",
      "Epoch 59/200\n",
      "1324/1324 [==============================] - 65s 49ms/step - loss: 1.7096 - categorical_accuracy: 0.5585 - val_loss: 2.6309 - val_categorical_accuracy: 0.4730\n",
      "Epoch 60/200\n",
      "1324/1324 [==============================] - 68s 51ms/step - loss: 1.7146 - categorical_accuracy: 0.5572 - val_loss: 2.6475 - val_categorical_accuracy: 0.4696\n",
      "Epoch 61/200\n",
      "1324/1324 [==============================] - 64s 49ms/step - loss: 1.7068 - categorical_accuracy: 0.5581 - val_loss: 2.7158 - val_categorical_accuracy: 0.4460\n",
      "Epoch 62/200\n",
      "1324/1324 [==============================] - 66s 50ms/step - loss: 1.6881 - categorical_accuracy: 0.5594 - val_loss: 2.6169 - val_categorical_accuracy: 0.4798\n",
      "Epoch 63/200\n",
      "1324/1324 [==============================] - 67s 50ms/step - loss: 1.6779 - categorical_accuracy: 0.5655 - val_loss: 2.6738 - val_categorical_accuracy: 0.4783\n",
      "Epoch 64/200\n",
      "1324/1324 [==============================] - 67s 51ms/step - loss: 1.6727 - categorical_accuracy: 0.5652 - val_loss: 2.7290 - val_categorical_accuracy: 0.4537\n",
      "Epoch 65/200\n",
      "1324/1324 [==============================] - 67s 51ms/step - loss: 1.6727 - categorical_accuracy: 0.5662 - val_loss: 2.6470 - val_categorical_accuracy: 0.4711\n",
      "Epoch 66/200\n",
      "1324/1324 [==============================] - 67s 50ms/step - loss: 1.6525 - categorical_accuracy: 0.5710 - val_loss: 2.6449 - val_categorical_accuracy: 0.4726\n",
      "Epoch 67/200\n",
      "1324/1324 [==============================] - 67s 50ms/step - loss: 1.6527 - categorical_accuracy: 0.5692 - val_loss: 2.6472 - val_categorical_accuracy: 0.4675\n",
      "Epoch 68/200\n",
      "1324/1324 [==============================] - 69s 52ms/step - loss: 1.6546 - categorical_accuracy: 0.5698 - val_loss: 2.6252 - val_categorical_accuracy: 0.4783\n",
      "Epoch 69/200\n",
      "1324/1324 [==============================] - 72s 54ms/step - loss: 1.6480 - categorical_accuracy: 0.5705 - val_loss: 2.6358 - val_categorical_accuracy: 0.4745\n",
      "Epoch 70/200\n",
      "1324/1324 [==============================] - 69s 52ms/step - loss: 1.6395 - categorical_accuracy: 0.5745 - val_loss: 2.6795 - val_categorical_accuracy: 0.4775\n",
      "Epoch 71/200\n",
      "1324/1324 [==============================] - 71s 54ms/step - loss: 1.6202 - categorical_accuracy: 0.5762 - val_loss: 2.6803 - val_categorical_accuracy: 0.4741\n",
      "Epoch 72/200\n",
      "1324/1324 [==============================] - 73s 55ms/step - loss: 1.6258 - categorical_accuracy: 0.5751 - val_loss: 2.6824 - val_categorical_accuracy: 0.4730\n",
      "Epoch 73/200\n",
      "1324/1324 [==============================] - 72s 54ms/step - loss: 1.6139 - categorical_accuracy: 0.5787 - val_loss: 2.8020 - val_categorical_accuracy: 0.4632\n",
      "Epoch 74/200\n",
      "1324/1324 [==============================] - 71s 53ms/step - loss: 1.6064 - categorical_accuracy: 0.5821 - val_loss: 2.7798 - val_categorical_accuracy: 0.4541\n",
      "Epoch 75/200\n",
      "1324/1324 [==============================] - 71s 53ms/step - loss: 1.6007 - categorical_accuracy: 0.5817 - val_loss: 2.7128 - val_categorical_accuracy: 0.4815\n",
      "Epoch 76/200\n",
      "1324/1324 [==============================] - 69s 52ms/step - loss: 1.5996 - categorical_accuracy: 0.5826 - val_loss: 2.7056 - val_categorical_accuracy: 0.4853\n",
      "Epoch 77/200\n",
      "1324/1324 [==============================] - 69s 52ms/step - loss: 1.5897 - categorical_accuracy: 0.5835 - val_loss: 2.7641 - val_categorical_accuracy: 0.4807\n",
      "Epoch 78/200\n",
      "1324/1324 [==============================] - 58s 44ms/step - loss: 1.5821 - categorical_accuracy: 0.5850 - val_loss: 2.7508 - val_categorical_accuracy: 0.4717\n",
      "Epoch 79/200\n",
      "1324/1324 [==============================] - 56s 42ms/step - loss: 1.5782 - categorical_accuracy: 0.5857 - val_loss: 2.6809 - val_categorical_accuracy: 0.4790\n",
      "Epoch 80/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 1.5712 - categorical_accuracy: 0.5859 - val_loss: 2.7398 - val_categorical_accuracy: 0.4751\n",
      "Epoch 81/200\n",
      "1324/1324 [==============================] - 57s 43ms/step - loss: 1.5700 - categorical_accuracy: 0.5869 - val_loss: 2.7851 - val_categorical_accuracy: 0.4756\n",
      "Epoch 82/200\n",
      "1324/1324 [==============================] - 56s 42ms/step - loss: 1.5577 - categorical_accuracy: 0.5895 - val_loss: 2.7557 - val_categorical_accuracy: 0.4792\n",
      "Epoch 83/200\n",
      "1324/1324 [==============================] - 58s 43ms/step - loss: 1.5516 - categorical_accuracy: 0.5920 - val_loss: 2.7556 - val_categorical_accuracy: 0.4826\n",
      "Epoch 84/200\n",
      "1324/1324 [==============================] - 63s 48ms/step - loss: 1.5575 - categorical_accuracy: 0.5886 - val_loss: 2.8186 - val_categorical_accuracy: 0.4777\n",
      "Epoch 85/200\n",
      "1324/1324 [==============================] - 59s 45ms/step - loss: 1.5538 - categorical_accuracy: 0.5911 - val_loss: 2.7957 - val_categorical_accuracy: 0.4805\n",
      "Epoch 86/200\n",
      "1324/1324 [==============================] - 51s 38ms/step - loss: 1.5469 - categorical_accuracy: 0.5936 - val_loss: 2.7986 - val_categorical_accuracy: 0.4853\n",
      "Epoch 87/200\n",
      "1324/1324 [==============================] - 56s 42ms/step - loss: 1.5368 - categorical_accuracy: 0.5936 - val_loss: 2.7435 - val_categorical_accuracy: 0.4805\n",
      "Epoch 88/200\n",
      "1324/1324 [==============================] - 65s 49ms/step - loss: 1.5275 - categorical_accuracy: 0.5959 - val_loss: 2.8868 - val_categorical_accuracy: 0.4688\n",
      "Epoch 89/200\n",
      " 519/1324 [==========>...................] - ETA: 40s - loss: 1.5019 - categorical_accuracy: 0.6030"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mdaniyalk/Documents/github/work/Google-IsolatedSignLanguage-Recognition/test.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mdaniyalk/Documents/github/work/Google-IsolatedSignLanguage-Recognition/test.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_train \u001b[39m=\u001b[39m model_LSTM\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_val,y_val), callbacks\u001b[39m=\u001b[39;49m[callbacks])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_train = model_LSTM.fit(X_train, y_train, epochs=200, batch_size=64,validation_data=(X_val,y_val), callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 20, 279)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 20, 256)      548864      ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " drop_1 (Dropout)               (None, 20, 256)      0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 512),        1574912     ['drop_1[0][0]']                 \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " concat_1 (Concatenate)         (None, 1536)         0           ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_2[0][1]',                 \n",
      "                                                                  'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         1573888     ['concat_1[0][0]']               \n",
      "                                                                                                  \n",
      " drop_2 (Dropout)               (None, 1024)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 250)          256250      ['drop_2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,953,914\n",
      "Trainable params: 3,953,914\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "inputs = tf.keras.layers.Input(shape=(20,279), name='inputs')\n",
    "x_1= tf.keras.layers.LSTM(256, return_sequences=True, activation='relu', name='lstm_1')(inputs)\n",
    "x = tf.keras.layers.Dropout(0.2, name='drop_1')(x_1)\n",
    "x, w, h= tf.keras.layers.LSTM(512, return_sequences=False, activation='relu', return_state=True, name='lstm_2')(x)\n",
    "# x = tf.keras.layers.LSTM(128, return_sequences=False, activation='relu')(x, initial_state=[w, h])\n",
    "concat = tf.keras.layers.concatenate([x, w, h], name='concat_1')\n",
    "# flatten = tf.keras.layers.Flatten(concat)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu', name='dense_1')(concat)\n",
    "x = tf.keras.layers.Dropout(0.2, name='drop_2')(x)\n",
    "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "out = tf.keras.layers.Dense(250, activation='softmax', name='outputs')(x)\n",
    "model_LSTM_2 = tf.keras.Model(inputs, out)\n",
    "model_LSTM_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1324/1324 [==============================] - 201s 151ms/step - loss: 5.1402 - categorical_accuracy: 0.0175 - val_loss: 4.7274 - val_categorical_accuracy: 0.0429\n",
      "Epoch 2/10\n",
      " 598/1324 [============>.................] - ETA: 1:56 - loss: 4.6446 - categorical_accuracy: 0.0514"
     ]
    }
   ],
   "source": [
    "model_LSTM_2.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_train = model_LSTM_2.fit(X_train, y_train, epochs=10, batch_size=64,validation_data=(X_val,y_val), callbacks=[callbacks])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
